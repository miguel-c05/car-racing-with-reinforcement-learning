{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6f18baea",
   "metadata": {},
   "source": [
    "## 1. Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c00c546e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.6.0+cu124\n",
      "CUDA available: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<frozen importlib._bootstrap>:488: RuntimeWarning: Your system is avx2 capable but pygame was not built with support for it. The performance of some of your blits could be adversely affected. Consider enabling compile time detection with environment variables like PYGAME_DETECT_AVX2=1 if you are compiling without cross compilation.\n",
      "c:\\Users\\migue\\anaconda3\\envs\\rl-racing\\Lib\\site-packages\\pygame\\pkgdata.py:25: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  from pkg_resources import resource_stream, resource_exists\n"
     ]
    }
   ],
   "source": [
    "import gymnasium as gym\n",
    "import numpy as np\n",
    "import torch\n",
    "from stable_baselines3.common.env_util import make_vec_env\n",
    "from stable_baselines3.common.vec_env import SubprocVecEnv\n",
    "\n",
    "# Import custom modules\n",
    "from customization import *\n",
    "from learning import Driver\n",
    "\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cacfe311",
   "metadata": {},
   "source": [
    "## 2. Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7f06c603",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuration:\n",
      "  Training environments: 2\n",
      "  Total timesteps: 100,000\n",
      "  Save frequency: 10,000\n",
      "  Eval frequency: 10,000\n"
     ]
    }
   ],
   "source": [
    "# Training configuration\n",
    "NUM_ENVS = 2  # Number of parallel training environments\n",
    "TOTAL_TIMESTEPS = 100_000  # Total training steps\n",
    "SAVE_FREQ = 10_000  # Save checkpoint every N steps\n",
    "EVAL_FREQ = SAVE_FREQ  # Evaluate every N steps\n",
    "N_EVAL_EPISODES = 5  # Number of episodes per evaluation\n",
    "\n",
    "# Directories\n",
    "CHECKPOINT_DIR = \"./modified_models/checkpoints/\"\n",
    "LOG_DIR = \"./logs/modified/\"\n",
    "BEST_MODEL_DIR = \"./modified_models/best_model/\"\n",
    "\n",
    "print(f\"Configuration:\")\n",
    "print(f\"  Training environments: {NUM_ENVS}\")\n",
    "print(f\"  Total timesteps: {TOTAL_TIMESTEPS:,}\")\n",
    "print(f\"  Save frequency: {SAVE_FREQ:,}\")\n",
    "print(f\"  Eval frequency: {EVAL_FREQ:,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73baa2bc",
   "metadata": {},
   "source": [
    "## 3. Create Vectorized Custom Environments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "40befb9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created 2 training environments\n",
      "Observation space: Box(0, 255, (84, 96, 3), uint8)\n",
      "Action space: Box([-1.  0.  0.], 1.0, (3,), float32)\n"
     ]
    }
   ],
   "source": [
    "train_env = make_vec_envs(num_envs=NUM_ENVS)\n",
    "\n",
    "print(f\"Created {NUM_ENVS} training environments\")\n",
    "print(f\"Observation space: {train_env.observation_space}\")\n",
    "print(f\"Action space: {train_env.action_space}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41e2bc49",
   "metadata": {},
   "source": [
    "## 4. Create Evaluation Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "19e020df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created evaluation environment\n",
      "Eval Observation space: Box(0, 255, (12, 84, 96), uint8)\n"
     ]
    }
   ],
   "source": [
    "from stable_baselines3.common.vec_env import VecFrameStack, VecTransposeImage\n",
    "\n",
    "# Create evaluation environment\n",
    "# Usamos a mesma factory, mas precisamos aplicar manualmente os wrappers\n",
    "# que o Driver aplica internamente no treino (Transpose + FrameStack).\n",
    "eval_env = make_vec_envs(num_envs=1)\n",
    "\n",
    "# 1. Transpose from (H, W, C) -> (C, H, W)\n",
    "# Isso coloca os canais de cor no início, padrão PyTorch/SB3\n",
    "eval_env = VecTransposeImage(eval_env)\n",
    "\n",
    "# 2. Stack Frames\n",
    "# O erro \"expected (12, 84, 96)\" indica 4 frames de 3 canais (4*3=12)\n",
    "eval_env = VecFrameStack(eval_env, n_stack=4)\n",
    "\n",
    "print(f\"Created evaluation environment\")\n",
    "print(f\"Eval Observation space: {eval_env.observation_space}\") \n",
    "# Deve imprimir: Box(0, 255, (12, 84, 96), uint8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39894528",
   "metadata": {},
   "source": [
    "## 5. Initialize Driver with PPO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "151cc0e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Driver initialized successfully!\n",
      "Model device: cuda\n",
      "VecEnv has 2 environments (includes FrameStack wrapper)\n"
     ]
    }
   ],
   "source": [
    "# Create the Driver (wraps PPO model with training logic)\n",
    "driver = Driver(\n",
    "    vec_env=train_env,\n",
    "    eval_env=eval_env,\n",
    ")\n",
    "\n",
    "print(f\"Driver initialized successfully!\")\n",
    "print(f\"Model device: {driver.model.device}\")\n",
    "print(f\"VecEnv has {driver.vec_env.num_envs} environments (includes FrameStack wrapper)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e53ffbf",
   "metadata": {},
   "source": [
    "## 6. Train the Model from Scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cb6b7d87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training...\n",
      "Training for 100,000 timesteps\n",
      "Checkpoints will be saved to: ./modified_models/checkpoints/\n",
      "Best model will be saved to: ./modified_models/best_model/\n",
      "TensorBoard logs: ./logs/modified/\n",
      "\n",
      "To monitor training, run in a terminal:\n",
      "  tensorboard --logdir ./logs/modified/\n",
      "\n",
      "==================================================\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10762b1eb5984d6eb22b11689739686c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\migue\\anaconda3\\envs\\rl-racing\\Lib\\site-packages\\stable_baselines3\\common\\callbacks.py:418: UserWarning: Training and eval env are not of the same type<stable_baselines3.common.vec_env.vec_transpose.VecTransposeImage object at 0x000001D3912D23F0> != <stable_baselines3.common.vec_env.vec_frame_stack.VecFrameStack object at 0x000001D391645BE0>\n",
      "  warnings.warn(\"Training and eval env are not of the same type\" f\"{self.training_env} != {self.eval_env}\")\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Eval num_timesteps=10000, episode_reward=25.84 +/- 6.52\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Eval num_timesteps=10000, episode_reward=25.84 +/- 6.52\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Episode length: 54.60 +/- 2.42\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Episode length: 54.60 +/- 2.42\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">New best mean reward!\n",
       "</pre>\n"
      ],
      "text/plain": [
       "New best mean reward!\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Eval num_timesteps=20000, episode_reward=25.84 +/- 3.24\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Eval num_timesteps=20000, episode_reward=25.84 +/- 3.24\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Episode length: 52.60 +/- 0.49\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Episode length: 52.60 +/- 0.49\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">New best mean reward!\n",
       "</pre>\n"
      ],
      "text/plain": [
       "New best mean reward!\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Eval num_timesteps=30000, episode_reward=-78.27 +/- 89.58\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Eval num_timesteps=30000, episode_reward=-78.27 +/- 89.58\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Episode length: 622.80 +/- 461.97\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Episode length: 622.80 +/- 461.97\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Eval num_timesteps=40000, episode_reward=516.33 +/- 1.12\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Eval num_timesteps=40000, episode_reward=516.33 +/- 1.12\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Episode length: 1000.00 +/- 0.00\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Episode length: 1000.00 +/- 0.00\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">New best mean reward!\n",
       "</pre>\n"
      ],
      "text/plain": [
       "New best mean reward!\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Eval num_timesteps=50000, episode_reward=516.24 +/- 1.62\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Eval num_timesteps=50000, episode_reward=516.24 +/- 1.62\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Episode length: 1000.00 +/- 0.00\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Episode length: 1000.00 +/- 0.00\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Eval num_timesteps=60000, episode_reward=516.16 +/- 0.71\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Eval num_timesteps=60000, episode_reward=516.16 +/- 0.71\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Episode length: 1000.00 +/- 0.00\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Episode length: 1000.00 +/- 0.00\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Eval num_timesteps=70000, episode_reward=530.72 +/- 1.72\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Eval num_timesteps=70000, episode_reward=530.72 +/- 1.72\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Episode length: 1000.00 +/- 0.00\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Episode length: 1000.00 +/- 0.00\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">New best mean reward!\n",
       "</pre>\n"
      ],
      "text/plain": [
       "New best mean reward!\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Eval num_timesteps=80000, episode_reward=531.32 +/- 0.74\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Eval num_timesteps=80000, episode_reward=531.32 +/- 0.74\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Episode length: 1000.00 +/- 0.00\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Episode length: 1000.00 +/- 0.00\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">New best mean reward!\n",
       "</pre>\n"
      ],
      "text/plain": [
       "New best mean reward!\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Eval num_timesteps=90000, episode_reward=528.90 +/- 3.24\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Eval num_timesteps=90000, episode_reward=528.90 +/- 3.24\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Episode length: 1000.00 +/- 0.00\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Episode length: 1000.00 +/- 0.00\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Eval num_timesteps=100000, episode_reward=533.69 +/- 6.90\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Eval num_timesteps=100000, episode_reward=533.69 +/- 6.90\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Episode length: 1000.00 +/- 0.00\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Episode length: 1000.00 +/- 0.00\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">New best mean reward!\n",
       "</pre>\n"
      ],
      "text/plain": [
       "New best mean reward!\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "Training completed!\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "print(\"Starting training...\")\n",
    "print(f\"Training for {TOTAL_TIMESTEPS:,} timesteps\")\n",
    "print(f\"Checkpoints will be saved to: {CHECKPOINT_DIR}\")\n",
    "print(f\"Best model will be saved to: {BEST_MODEL_DIR}\")\n",
    "print(f\"TensorBoard logs: {LOG_DIR}\")\n",
    "print(\"\\nTo monitor training, run in a terminal:\")\n",
    "print(f\"  tensorboard --logdir {LOG_DIR}\")\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "\n",
    "driver.train()\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"Training completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "521729e2",
   "metadata": {},
   "source": [
    "## 7. Resume Training from Checkpoint (Optional)\n",
    "\n",
    "Use this cell if you want to resume training from the latest checkpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "102af664",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resume training from latest checkpoint\n",
    "# You can change the number of workers if needed\n",
    "\n",
    "NUM_ENVS_RESUME = 4  # Optional: change number of workers for resumed training\n",
    "\n",
    "driver.resume_training(\n",
    "    target_steps=TOTAL_TIMESTEPS,\n",
    "    num_envs=NUM_ENVS_RESUME  # Set to None to keep same number of envs\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dca1f05",
   "metadata": {},
   "source": [
    "## 8. Save Final Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4adc5de5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to: ./modified_models/best_model//ppo_custom_env_final.zip\n",
      "Final model saved to: ./modified_models/best_model//ppo_custom_env_final.zip\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\migue\\anaconda3\\envs\\rl-racing\\Lib\\site-packages\\stable_baselines3\\common\\save_util.py:284: UserWarning: Path 'modified_models\\best_model' does not exist. Will create it.\n",
      "  warnings.warn(f\"Path '{path.parent}' does not exist. Will create it.\")\n"
     ]
    }
   ],
   "source": [
    "# Save the final trained model\n",
    "final_model_path = f\"{BEST_MODEL_DIR}/ppo_custom_env_final.zip\"\n",
    "driver.save(final_model_path)\n",
    "print(f\"Final model saved to: {final_model_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ead9a7e5",
   "metadata": {},
   "source": [
    "## 9. Close Environments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a4f5442c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All environments closed successfully!\n"
     ]
    }
   ],
   "source": [
    "# Close all environments\n",
    "train_env.close()\n",
    "eval_env.close()\n",
    "\n",
    "print(\"All environments closed successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16ce3019",
   "metadata": {},
   "source": [
    "## 10. Test the Trained Model (Optional)\n",
    "\n",
    "Visualize the trained agent playing the game."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d9d48c52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model from: ./modified_models/best_model//ppo_custom_env_final.zip\n",
      "\n",
      "Episode 1/3\n",
      "\n",
      "Episode 1/3\n",
      "  Steps: 1000\n",
      "  Total Reward: 527.33\n",
      "  Steps: 1000\n",
      "  Total Reward: 527.33\n",
      "\n",
      "Episode 2/3\n",
      "\n",
      "Episode 2/3\n",
      "  Steps: 1000\n",
      "  Total Reward: 527.37\n",
      "  Steps: 1000\n",
      "  Total Reward: 527.37\n",
      "\n",
      "Episode 3/3\n",
      "\n",
      "Episode 3/3\n",
      "  Steps: 1000\n",
      "  Total Reward: 532.88\n",
      "  Steps: 1000\n",
      "  Total Reward: 532.88\n",
      "Testing complete!\n",
      "Testing complete!\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.vec_env import VecFrameStack, VecTransposeImage\n",
    "\n",
    "# 1. Load the best model\n",
    "best_model_path = f\"{BEST_MODEL_DIR}/ppo_custom_env_final.zip\"\n",
    "# Se der erro de arquivo não encontrado, tente o final:\n",
    "# best_model_path = \"./modified_models/ppo_custom_env_final.zip\"\n",
    "\n",
    "print(f\"Loading model from: {best_model_path}\")\n",
    "model = PPO.load(best_model_path)\n",
    "\n",
    "# 2. Create test env & Apply Wrappers manually\n",
    "test_env = make_vec_envs(num_envs=1)\n",
    "test_env = VecTransposeImage(test_env)\n",
    "test_env = VecFrameStack(test_env, n_stack=4)\n",
    "\n",
    "NUM_TEST_EPISODES = 3\n",
    "\n",
    "try:\n",
    "    for episode in range(NUM_TEST_EPISODES):\n",
    "        obs = test_env.reset()\n",
    "        done = False\n",
    "        total_reward = 0\n",
    "        step_count = 0\n",
    "        \n",
    "        print(f\"\\nEpisode {episode + 1}/{NUM_TEST_EPISODES}\")\n",
    "        \n",
    "        while not done:\n",
    "            # Predict action\n",
    "            action, _states = model.predict(obs, deterministic=True)\n",
    "            \n",
    "            # Step environment\n",
    "            obs, reward, done_array, info = test_env.step(action)\n",
    "            done = done_array[0] # VecEnv retorna array\n",
    "            total_reward += reward[0]\n",
    "            step_count += 1\n",
    "            \n",
    "            # --- VISUALIZATION LOGIC ---\n",
    "            # Obs shape agora é (1, 12, 84, 96) -> (Batch, Channels, H, W)\n",
    "            \n",
    "            # 1. Pegar o primeiro do batch e Transpor de volta para (H, W, C) para o OpenCV\n",
    "            # shape[0] é 12 (canais). Transpose (1, 2, 0) -> (84, 96, 12)\n",
    "            agent_view = np.transpose(obs[0], (1, 2, 0))\n",
    "            \n",
    "            # 2. Pegar apenas os últimos 3 canais (frame mais recente)\n",
    "            current_frame_rgb = agent_view[:, :, -3:]\n",
    "            \n",
    "            # 3. Converter RGB para BGR\n",
    "            frame_bgr = cv2.cvtColor(current_frame_rgb.astype(np.uint8), cv2.COLOR_RGB2BGR)\n",
    "            \n",
    "            # 4. Upscale\n",
    "            frame_upscaled = cv2.resize(frame_bgr, (480, 420), interpolation=cv2.INTER_NEAREST)\n",
    "            \n",
    "            cv2.imshow(\"Agent View (Stacked)\", frame_upscaled)\n",
    "            \n",
    "            if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                done = True\n",
    "                break\n",
    "        \n",
    "        print(f\"  Steps: {step_count}\")\n",
    "        print(f\"  Total Reward: {total_reward:.2f}\")\n",
    "        \n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "except KeyboardInterrupt:\n",
    "    print(\"\\nInterrupted by user\")\n",
    "finally:\n",
    "    test_env.close()\n",
    "    cv2.destroyAllWindows()\n",
    "    print(\"Testing complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4518093e",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "- Monitor training with TensorBoard: `tensorboard --logdir ./logs/modified/`\n",
    "- Compare performance with base model (train_base_model.ipynb)\n",
    "- Tune reward hyperparameters in config.py\n",
    "- Analyze the effect of optimal line following\n",
    "- Test different racing tracks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f18cdc3",
   "metadata": {},
   "source": [
    "## 11. Play with Best Model\n",
    "\n",
    "Load and visualize the best model from training (saved by EvalCallback)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "36694bef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading best model from: ./modified_models/best_model//ppo_custom_env_final\n",
      "\n",
      "Playing 5 episodes with best model...\n",
      "Press 'q' to quit\n",
      "\n",
      "\n",
      "Playing 5 episodes with best model...\n",
      "Press 'q' to quit\n",
      "\n",
      "Episode 1/5 Episode 1/5 - Steps:  505 | Reward:  284.00\n",
      "- Steps:  505 | Reward:  284.00\n",
      "Episode 2/5 Episode 2/5 - Steps:  806 | Reward:  433.73\n",
      "- Steps:  806 | Reward:  433.73\n",
      "Episode 3/5 Episode 3/5 - Steps: 1000 | Reward:  532.24\n",
      "- Steps: 1000 | Reward:  532.24\n",
      "Episode 4/5 Episode 4/5 - Steps:  836 | Reward:  444.13\n",
      "- Steps:  836 | Reward:  444.13\n",
      "Episode 5/5 Episode 5/5 - Steps:   83 | Reward:   72.37\n",
      "- Steps:   83 | Reward:   72.37\n",
      "\n",
      "Playback complete!\n",
      "\n",
      "Playback complete!\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.vec_env import VecFrameStack, VecTransposeImage\n",
    "\n",
    "# Load the best model (saved by EvalCallback during training)\n",
    "best_model_path = f\"{BEST_MODEL_DIR}/ppo_custom_env_final\"\n",
    "\n",
    "print(f\"Loading best model from: {best_model_path}\")\n",
    "model = PPO.load(best_model_path)\n",
    "\n",
    "# Create test environment with proper wrappers\n",
    "test_env = make_vec_envs(num_envs=1)\n",
    "test_env = VecTransposeImage(test_env)\n",
    "test_env = VecFrameStack(test_env, n_stack=4)\n",
    "\n",
    "NUM_EPISODES = 5\n",
    "\n",
    "print(f\"\\nPlaying {NUM_EPISODES} episodes with best model...\")\n",
    "print(\"Press 'q' to quit\\n\")\n",
    "\n",
    "try:\n",
    "    for episode in range(NUM_EPISODES):\n",
    "        obs = test_env.reset()\n",
    "        done = False\n",
    "        total_reward = 0\n",
    "        step_count = 0\n",
    "        \n",
    "        print(f\"Episode {episode + 1}/{NUM_EPISODES}\", end=\" \", flush=True)\n",
    "        \n",
    "        while not done:\n",
    "            # Predict action\n",
    "            action, _states = model.predict(obs, deterministic=True)\n",
    "            \n",
    "            # Step environment\n",
    "            obs, reward, done_array, info = test_env.step(action)\n",
    "            done = done_array[0]\n",
    "            total_reward += reward[0]\n",
    "            step_count += 1\n",
    "            \n",
    "            # Visualize: obs shape is (1, 12, 84, 96) -> (Batch, Channels, H, W)\n",
    "            # Transpose to (H, W, C) and take last 3 channels (current frame)\n",
    "            agent_view = np.transpose(obs[0], (1, 2, 0))[:, :, -3:]\n",
    "            \n",
    "            # Convert RGB to BGR and upscale\n",
    "            frame_bgr = cv2.cvtColor(agent_view.astype(np.uint8), cv2.COLOR_RGB2BGR)\n",
    "            frame_upscaled = cv2.resize(frame_bgr, (480, 420), interpolation=cv2.INTER_NEAREST)\n",
    "            \n",
    "            cv2.imshow(\"Best Model Playing\", frame_upscaled)\n",
    "            \n",
    "            if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                done = True\n",
    "                break\n",
    "        \n",
    "        print(f\"- Steps: {step_count:4d} | Reward: {total_reward:7.2f}\")\n",
    "        \n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "except KeyboardInterrupt:\n",
    "    print(\"\\nInterrupted by user\")\n",
    "finally:\n",
    "    test_env.close()\n",
    "    cv2.destroyAllWindows()\n",
    "    print(\"\\nPlayback complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39487ac9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Videos will be saved to: videos/100000\n",
      "Loading model from: ./modified_models/best_model//best_model.zip\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'modified_models\\\\best_model\\\\best_model.zip.zip'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[20]\u001b[39m\u001b[32m, line 17\u001b[39m\n\u001b[32m     15\u001b[39m best_model_path = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mBEST_MODEL_DIR\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m/best_model.zip\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     16\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mLoading model from: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbest_model_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m17\u001b[39m model = \u001b[43mPPO\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbest_model_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     19\u001b[39m \u001b[38;5;66;03m# Number of episodes to record\u001b[39;00m\n\u001b[32m     20\u001b[39m NUM_RECORD_EPISODES = \u001b[32m3\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\migue\\anaconda3\\envs\\rl-racing\\Lib\\site-packages\\stable_baselines3\\common\\base_class.py:681\u001b[39m, in \u001b[36mBaseAlgorithm.load\u001b[39m\u001b[34m(cls, path, env, device, custom_objects, print_system_info, force_reset, **kwargs)\u001b[39m\n\u001b[32m    678\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m== CURRENT SYSTEM INFO ==\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    679\u001b[39m     get_system_info()\n\u001b[32m--> \u001b[39m\u001b[32m681\u001b[39m data, params, pytorch_variables = \u001b[43mload_from_zip_file\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    682\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    683\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    684\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcustom_objects\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcustom_objects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    685\u001b[39m \u001b[43m    \u001b[49m\u001b[43mprint_system_info\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprint_system_info\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    686\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    688\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m data \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[33m\"\u001b[39m\u001b[33mNo data found in the saved file\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    689\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m params \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[33m\"\u001b[39m\u001b[33mNo params found in the saved file\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\migue\\anaconda3\\envs\\rl-racing\\Lib\\site-packages\\stable_baselines3\\common\\save_util.py:403\u001b[39m, in \u001b[36mload_from_zip_file\u001b[39m\u001b[34m(load_path, load_data, custom_objects, device, verbose, print_system_info)\u001b[39m\n\u001b[32m    376\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mload_from_zip_file\u001b[39m(\n\u001b[32m    377\u001b[39m     load_path: Union[\u001b[38;5;28mstr\u001b[39m, pathlib.Path, io.BufferedIOBase],\n\u001b[32m    378\u001b[39m     load_data: \u001b[38;5;28mbool\u001b[39m = \u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    382\u001b[39m     print_system_info: \u001b[38;5;28mbool\u001b[39m = \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m    383\u001b[39m ) -> \u001b[38;5;28mtuple\u001b[39m[Optional[\u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any]], TensorDict, Optional[TensorDict]]:\n\u001b[32m    384\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    385\u001b[39m \u001b[33;03m    Load model data from a .zip archive\u001b[39;00m\n\u001b[32m    386\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    401\u001b[39m \u001b[33;03m        and dict of pytorch variables\u001b[39;00m\n\u001b[32m    402\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m403\u001b[39m     file = \u001b[43mopen_path\u001b[49m\u001b[43m(\u001b[49m\u001b[43mload_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mr\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msuffix\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mzip\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    405\u001b[39m     \u001b[38;5;66;03m# set device to cpu if cuda is not available\u001b[39;00m\n\u001b[32m    406\u001b[39m     device = get_device(device=device)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\migue\\anaconda3\\envs\\rl-racing\\Lib\\functools.py:912\u001b[39m, in \u001b[36msingledispatch.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kw)\u001b[39m\n\u001b[32m    908\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m args:\n\u001b[32m    909\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfuncname\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m requires at least \u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m    910\u001b[39m                     \u001b[33m'\u001b[39m\u001b[33m1 positional argument\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m912\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdispatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__class__\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\migue\\anaconda3\\envs\\rl-racing\\Lib\\site-packages\\stable_baselines3\\common\\save_util.py:240\u001b[39m, in \u001b[36mopen_path_str\u001b[39m\u001b[34m(path, mode, verbose, suffix)\u001b[39m\n\u001b[32m    225\u001b[39m \u001b[38;5;129m@open_path\u001b[39m.register(\u001b[38;5;28mstr\u001b[39m)\n\u001b[32m    226\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mopen_path_str\u001b[39m(path: \u001b[38;5;28mstr\u001b[39m, mode: \u001b[38;5;28mstr\u001b[39m, verbose: \u001b[38;5;28mint\u001b[39m = \u001b[32m0\u001b[39m, suffix: Optional[\u001b[38;5;28mstr\u001b[39m] = \u001b[38;5;28;01mNone\u001b[39;00m) -> io.BufferedIOBase:\n\u001b[32m    227\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    228\u001b[39m \u001b[33;03m    Open a path given by a string. If writing to the path, the function ensures\u001b[39;00m\n\u001b[32m    229\u001b[39m \u001b[33;03m    that the path exists.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    238\u001b[39m \u001b[33;03m    :return:\u001b[39;00m\n\u001b[32m    239\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m240\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mopen_path_pathlib\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpathlib\u001b[49m\u001b[43m.\u001b[49m\u001b[43mPath\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msuffix\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\migue\\anaconda3\\envs\\rl-racing\\Lib\\site-packages\\stable_baselines3\\common\\save_util.py:291\u001b[39m, in \u001b[36mopen_path_pathlib\u001b[39m\u001b[34m(path, mode, verbose, suffix)\u001b[39m\n\u001b[32m    285\u001b[39m         path.parent.mkdir(exist_ok=\u001b[38;5;28;01mTrue\u001b[39;00m, parents=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m    287\u001b[39m \u001b[38;5;66;03m# if opening was successful uses the open_path() function\u001b[39;00m\n\u001b[32m    288\u001b[39m \u001b[38;5;66;03m# if opening failed with IsADirectory|FileNotFound, calls open_path_pathlib\u001b[39;00m\n\u001b[32m    289\u001b[39m \u001b[38;5;66;03m#   with corrections\u001b[39;00m\n\u001b[32m    290\u001b[39m \u001b[38;5;66;03m# if reading failed with FileNotFoundError, calls open_path_pathlib with suffix\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m291\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mopen_path_pathlib\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msuffix\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\migue\\anaconda3\\envs\\rl-racing\\Lib\\site-packages\\stable_baselines3\\common\\save_util.py:272\u001b[39m, in \u001b[36mopen_path_pathlib\u001b[39m\u001b[34m(path, mode, verbose, suffix)\u001b[39m\n\u001b[32m    270\u001b[39m             path, suffix = newpath, \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    271\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m272\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m error\n\u001b[32m    273\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    274\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\migue\\anaconda3\\envs\\rl-racing\\Lib\\site-packages\\stable_baselines3\\common\\save_util.py:264\u001b[39m, in \u001b[36mopen_path_pathlib\u001b[39m\u001b[34m(path, mode, verbose, suffix)\u001b[39m\n\u001b[32m    262\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m mode == \u001b[33m\"\u001b[39m\u001b[33mr\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    263\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m264\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m open_path(\u001b[43mpath\u001b[49m\u001b[43m.\u001b[49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrb\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m, mode, verbose, suffix)\n\u001b[32m    265\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m error:\n\u001b[32m    266\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m suffix \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m suffix != \u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\migue\\anaconda3\\envs\\rl-racing\\Lib\\pathlib.py:1013\u001b[39m, in \u001b[36mPath.open\u001b[39m\u001b[34m(self, mode, buffering, encoding, errors, newline)\u001b[39m\n\u001b[32m   1011\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[32m   1012\u001b[39m     encoding = io.text_encoding(encoding)\n\u001b[32m-> \u001b[39m\u001b[32m1013\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio\u001b[49m\u001b[43m.\u001b[49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffering\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnewline\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: 'modified_models\\\\best_model\\\\best_model.zip.zip'"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.vec_env import VecFrameStack, VecTransposeImage\n",
    "from gymnasium.wrappers import RecordVideo\n",
    "\n",
    "# Create video directory based on training timesteps\n",
    "video_subfolder = f\"videos/{TOTAL_TIMESTEPS}\"\n",
    "os.makedirs(video_subfolder, exist_ok=True)\n",
    "\n",
    "print(f\"Videos will be saved to: {video_subfolder}\")\n",
    "\n",
    "# Load the best model\n",
    "best_model_path = f\"{BEST_MODEL_DIR}/ppo_custom_env_final.zip\"\n",
    "print(f\"Loading model from: {best_model_path}\")\n",
    "model = PPO.load(best_model_path)\n",
    "\n",
    "# Number of episodes to record\n",
    "NUM_RECORD_EPISODES = 3\n",
    "\n",
    "# Record episodes\n",
    "for episode_idx in range(NUM_RECORD_EPISODES):\n",
    "    print(f\"\\nRecording episode {episode_idx + 1}/{NUM_RECORD_EPISODES}...\")\n",
    "    \n",
    "    # Create environment with RecordVideo wrapper\n",
    "    env = gym.make(\"CarRacing-v3\", render_mode=\"rgb_array\")\n",
    "    env = CustomEnvironment(env)\n",
    "    \n",
    "    # Add RecordVideo wrapper\n",
    "    env = RecordVideo(\n",
    "        env,\n",
    "        video_folder=video_subfolder,\n",
    "        name_prefix=f\"episode_{episode_idx + 1}\",\n",
    "        episode_trigger=lambda x: True  # Record this episode\n",
    "    )\n",
    "    \n",
    "    # Reset environment\n",
    "    obs, info = env.reset(seed=1000 + episode_idx)\n",
    "    \n",
    "    # Stack frames manually for single environment\n",
    "    stacked_obs = np.stack([obs] * 4, axis=-1)\n",
    "    \n",
    "    done = False\n",
    "    total_reward = 0\n",
    "    step_count = 0\n",
    "    \n",
    "    while not done:\n",
    "        # Predict action\n",
    "        action, _states = model.predict(stacked_obs, deterministic=True)\n",
    "        \n",
    "        # Step environment\n",
    "        obs, reward, terminated, truncated, info = env.step(action)\n",
    "        done = terminated or truncated\n",
    "        \n",
    "        # Update frame stack\n",
    "        stacked_obs = np.concatenate([stacked_obs[:, :, 3:], obs], axis=-1)\n",
    "        \n",
    "        total_reward += reward\n",
    "        step_count += 1\n",
    "    \n",
    "    env.close()\n",
    "    \n",
    "    print(f\"  Steps: {step_count:4d} | Reward: {total_reward:7.2f}\")\n",
    "\n",
    "print(f\"\\n✓ All videos saved to: {video_subfolder}\")\n",
    "print(f\"Total episodes recorded: {NUM_RECORD_EPISODES}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca783080",
   "metadata": {},
   "source": [
    "## 12. Record Videos of Model Performance\n",
    "\n",
    "Record videos of the trained model playing and save them to the videos folder."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rl-racing",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
